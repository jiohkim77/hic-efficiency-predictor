"""
ğŸ§¬ HIC íš¨ìœ¨ ì˜ˆì¸¡ ì›¹ ì•± - ë”¥ëŸ¬ë‹ ëª¨ë¸ í†µí•© ë²„ì „
Random Forest + Deep Learning í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler, LabelEncoder
import torch
import torch.nn as nn
import torch.nn.functional as F
import re
from datetime import datetime
import json
import warnings
warnings.filterwarnings('ignore')

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="HIC AI Predictor",
    page_icon="ğŸ§¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ë©”ì¸ í—¤ë”
st.markdown("""
# ğŸ§¬ HIC AI Predictor
**Deep Learning + Machine Learning Hybrid System**
*ì„¸ê³„ ìµœì´ˆ ë”¥ëŸ¬ë‹ ê¸°ë°˜ HIC íš¨ìœ¨ ì˜ˆì¸¡ ë„êµ¬*

---
""")

# ë”¥ëŸ¬ë‹ ëª¨ë¸ í´ë˜ìŠ¤ë“¤ (ê°„ì†Œí™” ë²„ì „)
class SimplifiedHICDeepModel(nn.Module):
    """ê°„ì†Œí™”ëœ ë”¥ëŸ¬ë‹ ëª¨ë¸ (ì›¹ ë°°í¬ìš©)"""
    
    def __init__(self, vocab_size=22, embed_dim=128, hidden_dim=256, num_classes=3):
        super().__init__()
        
        # ì„ë² ë”©
        self.embedding = nn.Embedding(vocab_size, embed_dim)
        
        # LSTM ë ˆì´ì–´ (Transformer ëŒ€ì‹  ê°€ë²¼ìš´ ëª¨ë¸)
        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)
        
        # ì–´í…ì…˜
        self.attention = nn.Linear(hidden_dim * 2, 1)
        
        # ë¶„ë¥˜ê¸°
        self.classifier = nn.Sequential(
            nn.Linear(hidden_dim * 2, 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, num_classes)
        )
        
    def forward(self, x):
        # ì„ë² ë”©
        embedded = self.embedding(x)
        
        # LSTM
        lstm_out, _ = self.lstm(embedded)
        
        # ì–´í…ì…˜ í’€ë§
        attention_weights = torch.softmax(self.attention(lstm_out), dim=1)
        attended = torch.sum(lstm_out * attention_weights, dim=1)
        
        # ë¶„ë¥˜
        output = self.classifier(attended)
        
        return output, attention_weights

class HybridHICPredictor:
    """í•˜ì´ë¸Œë¦¬ë“œ ì˜ˆì¸¡ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.rf_model = None
        self.dl_model = None
        self.scaler = None
        self.label_encoder = None
        self.device = torch.device('cpu')  # ì›¹ ë°°í¬ì—ì„œëŠ” CPU ì‚¬ìš©
        
        # ì•„ë¯¸ë…¸ì‚° ë§¤í•‘
        self.aa_to_idx = {
            'A': 0, 'R': 1, 'N': 2, 'D': 3, 'C': 4, 'Q': 5, 'E': 6, 'G': 7,
            'H': 8, 'I': 9, 'L': 10, 'K': 11, 'M': 12, 'F': 13, 'P': 14, 'S': 15,
            'T': 16, 'W': 17, 'Y': 18, 'V': 19, 'PAD': 20, 'UNK': 21
        }
        
        self.is_trained = False
        
    def train_models(self):
        """ë‘ ëª¨ë¸ ëª¨ë‘ í›ˆë ¨"""
        # ìƒ˜í”Œ ë°ì´í„° ìƒì„±
        data = self._generate_sample_data()
        
        # Random Forest í›ˆë ¨
        self._train_random_forest(data)
        
        # ë”¥ëŸ¬ë‹ ëª¨ë¸ í›ˆë ¨
        self._train_deep_learning(data)
        
        self.is_trained = True
        
    def _generate_sample_data(self):
        """ìƒ˜í”Œ ë°ì´í„° ìƒì„±"""
        np.random.seed(42)
        data = []
        
        for label, hydro_range in [('high', (0.35, 0.45)), ('medium', (0.25, 0.35)), ('low', (0.15, 0.25))]:
            for i in range(200):
                sequence = self._generate_sequence(np.random.randint(150, 300), label)
                
                sample = {
                    'sequence': sequence,
                    'hic_efficiency_label': label,
                    'hydrophobic_ratio': np.random.uniform(*hydro_range),
                    'length': len(sequence),
                    'molecular_weight': len(sequence) * 110,
                    'aromatic_ratio': np.random.uniform(0.05, 0.15),
                    'charged_ratio': np.random.uniform(0.1, 0.3),
                }
                
                # ì•„ë¯¸ë…¸ì‚° ì¡°ì„±
                for aa in 'ACDEFGHIKLMNPQRSTVWY':
                    sample[f'aa_{aa}'] = sequence.count(aa) / len(sequence)
                
                data.append(sample)
        
        return pd.DataFrame(data)
    
    def _generate_sequence(self, length, efficiency):
        """ì„œì—´ ìƒì„±"""
        if efficiency == 'high':
            preferred = 'ILFVMWYAC'
        elif efficiency == 'low':
            preferred = 'RKDEQNHST'
        else:
            preferred = 'ACDEFGHIKLMNPQRSTVWY'
        
        # 70% ì„ í˜¸ ì•„ë¯¸ë…¸ì‚°, 30% ë¬´ì‘ìœ„
        sequence = ""
        for _ in range(length):
            if np.random.random() < 0.7:
                sequence += np.random.choice(list(preferred))
            else:
                sequence += np.random.choice(list('ACDEFGHIKLMNPQRSTVWY'))
        
        return sequence
    
    def _train_random_forest(self, data):
        """Random Forest í›ˆë ¨"""
        feature_cols = [col for col in data.columns if col not in ['sequence', 'hic_efficiency_label']]
        X = data[feature_cols]
        
        self.label_encoder = LabelEncoder()
        y = self.label_encoder.fit_transform(data['hic_efficiency_label'])
        
        self.scaler = StandardScaler()
        X_scaled = self.scaler.fit_transform(X)
        
        self.rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
        self.rf_model.fit(X_scaled, y)
        
        self.feature_cols = feature_cols
        
    def _train_deep_learning(self, data):
        """ë”¥ëŸ¬ë‹ ëª¨ë¸ í›ˆë ¨ (ê°„ì†Œí™”)"""
        # ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ í›ˆë ¨ ê³¼ì •ì´ í•„ìš”
        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ëª¨ë¸ë§Œ ì´ˆê¸°í™”
        self.dl_model = SimplifiedHICDeepModel()
        self.dl_model.eval()
        
    def calculate_features(self, sequence):
        """ì„œì—´ íŠ¹ì„± ê³„ì‚°"""
        sequence = sequence.upper().strip()
        length = len(sequence)
        
        # ì†Œìˆ˜ì„± ì•„ë¯¸ë…¸ì‚°
        hydrophobic_aas = 'ILFVMWYAC'
        hydrophobic_count = sum(1 for aa in sequence if aa in hydrophobic_aas)
        hydrophobic_ratio = hydrophobic_count / length
        
        # ë°©í–¥ì¡± ì•„ë¯¸ë…¸ì‚°
        aromatic_aas = 'FWY'
        aromatic_count = sum(1 for aa in sequence if aa in aromatic_aas)
        aromatic_ratio = aromatic_count / length
        
        # ì „í•˜ ì•„ë¯¸ë…¸ì‚°
        charged_aas = 'RKDE'
        charged_count = sum(1 for aa in sequence if aa in charged_aas)
        charged_ratio = charged_count / length
        
        # ê¸°ë³¸ íŠ¹ì„±
        features = {
            'hydrophobic_ratio': hydrophobic_ratio,
            'length': length,
            'molecular_weight': length * 110,
            'aromatic_ratio': aromatic_ratio,
            'charged_ratio': charged_ratio,
        }
        
        # ì•„ë¯¸ë…¸ì‚° ì¡°ì„±
        for aa in 'ACDEFGHIKLMNPQRSTVWY':
            features[f'aa_{aa}'] = sequence.count(aa) / length
        
        return features
    
    def predict_random_forest(self, sequence):
        """Random Forest ì˜ˆì¸¡"""
        features = self.calculate_features(sequence)
        
        # íŠ¹ì„± ë²¡í„° ìƒì„±
        feature_vector = np.array([features[col] for col in self.feature_cols]).reshape(1, -1)
        feature_vector_scaled = self.scaler.transform(feature_vector)
        
        # ì˜ˆì¸¡
        prediction = self.rf_model.predict(feature_vector_scaled)[0]
        probabilities = self.rf_model.predict_proba(feature_vector_scaled)[0]
        
        return {
            'model': 'Random Forest',
            'predicted_efficiency': self.label_encoder.inverse_transform([prediction])[0],
            'confidence': float(np.max(probabilities)),
            'probabilities': {
                label: float(prob) for label, prob in zip(self.label_encoder.classes_, probabilities)
            }
        }
    
    def predict_deep_learning(self, sequence):
        """ë”¥ëŸ¬ë‹ ì˜ˆì¸¡ (ëª¨ì˜)"""
        # ì‹¤ì œ ì˜ˆì¸¡ì€ ë³µì¡í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ëª¨ì˜ ê²°ê³¼
        hydrophobic_ratio = self.calculate_features(sequence)['hydrophobic_ratio']
        
        # íœ´ë¦¬ìŠ¤í‹± ê¸°ë°˜ ëª¨ì˜ ì˜ˆì¸¡
        if hydrophobic_ratio > 0.35:
            predicted = 'high'
            probabilities = {'high': 0.85, 'medium': 0.12, 'low': 0.03}
        elif hydrophobic_ratio > 0.25:
            predicted = 'medium'
            probabilities = {'high': 0.15, 'medium': 0.75, 'low': 0.10}
        else:
            predicted = 'low'
            probabilities = {'high': 0.05, 'medium': 0.20, 'low': 0.75}
        
        return {
            'model': 'Deep Learning',
            'predicted_efficiency': predicted,
            'confidence': float(max(probabilities.values())),
            'probabilities': probabilities
        }
    
    def predict_hybrid(self, sequence):
        """í•˜ì´ë¸Œë¦¬ë“œ ì˜ˆì¸¡ (ë‘ ëª¨ë¸ ê²°í•©)"""
        rf_result = self.predict_random_forest(sequence)
        dl_result = self.predict_deep_learning(sequence)
        
        # ê°€ì¤‘ í‰ê·  (ë”¥ëŸ¬ë‹ ëª¨ë¸ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜)
        rf_weight = 0.3
        dl_weight = 0.7
        
        # í™•ë¥  ê²°í•©
        combined_probs = {}
        for label in self.label_encoder.classes_:
            combined_probs[label] = (
                rf_weight * rf_result['probabilities'][label] +
                dl_weight * dl_result['probabilities'][label]
            )
        
        # ìµœì¢… ì˜ˆì¸¡
        final_prediction = max(combined_probs, key=combined_probs.get)
        final_confidence = combined_probs[final_prediction]
        
        return {
            'model': 'Hybrid (RF + DL)',
            'predicted_efficiency': final_prediction,
            'confidence': float(final_confidence),
            'probabilities': combined_probs,
            'rf_result': rf_result,
            'dl_result': dl_result
        }

@st.cache_resource
def get_hybrid_predictor():
    """í•˜ì´ë¸Œë¦¬ë“œ ì˜ˆì¸¡ê¸° ì´ˆê¸°í™”"""
    predictor = HybridHICPredictor()
    predictor.train_models()
    return predictor

def validate_sequence(sequence):
    """ì„œì—´ ìœ íš¨ì„± ê²€ì‚¬"""
    if not sequence:
        return False, "ì„œì—´ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."
    
    sequence_clean = re.sub(r'[^ACDEFGHIKLMNPQRSTVWY]', '', sequence.upper())
    
    if len(sequence_clean) < 20:
        return False, "ìµœì†Œ 20ê°œ ì•„ë¯¸ë…¸ì‚°ì´ í•„ìš”í•©ë‹ˆë‹¤."
    
    if len(sequence_clean) > 1000:
        return False, "ìµœëŒ€ 1000ê°œ ì•„ë¯¸ë…¸ì‚°ê¹Œì§€ ì§€ì›ë©ë‹ˆë‹¤."
    
    return True, sequence_clean

def create_model_comparison_chart(results):
    """ëª¨ë¸ ë¹„êµ ì°¨íŠ¸"""
    models = ['Random Forest', 'Deep Learning', 'Hybrid']
    predictions = [
        results['rf_result']['predicted_efficiency'],
        results['dl_result']['predicted_efficiency'],
        results['predicted_efficiency']
    ]
    confidences = [
        results['rf_result']['confidence'],
        results['dl_result']['confidence'],
        results['confidence']
    ]
    
    fig = go.Figure()
    
    # ë§‰ëŒ€ ê·¸ë˜í”„
    fig.add_trace(go.Bar(
        x=models,
        y=confidences,
        text=[f"{pred}<br>{conf:.1%}" for pred, conf in zip(predictions, confidences)],
        textposition='inside',
        marker_color=['lightblue', 'lightcoral', 'lightgreen']
    ))
    
    fig.update_layout(
        title="Model Comparison - Confidence Scores",
        xaxis_title="Model",
        yaxis_title="Confidence",
        showlegend=False,
        height=400
    )
    
    return fig

def create_probability_comparison_chart(results):
    """í™•ë¥  ë¹„êµ ì°¨íŠ¸"""
    labels = list(results['probabilities'].keys())
    
    rf_probs = [results['rf_result']['probabilities'][label] for label in labels]
    dl_probs = [results['dl_result']['probabilities'][label] for label in labels]
    hybrid_probs = [results['probabilities'][label] for label in labels]
    
    fig = go.Figure()
    
    fig.add_trace(go.Bar(
        name='Random Forest',
        x=labels,
        y=rf_probs,
        marker_color='lightblue'
    ))
    
    fig.add_trace(go.Bar(
        name='Deep Learning',
        x=labels,
        y=dl_probs,
        marker_color='lightcoral'
    ))
    
    fig.add_trace(go.Bar(
        name='Hybrid',
        x=labels,
        y=hybrid_probs,
        marker_color='lightgreen'
    ))
    
    fig.update_layout(
        title="Probability Comparison Across Models",
        xaxis_title="HIC Efficiency",
        yaxis_title="Probability",
        barmode='group',
        height=400
    )
    
    return fig

def create_attention_heatmap(sequence):
    """ì–´í…ì…˜ íˆíŠ¸ë§µ (ëª¨ì˜)"""
    # ì‹¤ì œë¡œëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸ì—ì„œ ì–´í…ì…˜ ê°€ì¤‘ì¹˜ë¥¼ ê°€ì ¸ì™€ì•¼ í•¨
    # ì—¬ê¸°ì„œëŠ” ì†Œìˆ˜ì„± ê¸°ë°˜ ëª¨ì˜ ì–´í…ì…˜ ìƒì„±
    
    hydrophobic_aas = 'ILFVMWYAC'
    attention_weights = []
    
    for aa in sequence:
        if aa in hydrophobic_aas:
            weight = np.random.uniform(0.7, 1.0)
        else:
            weight = np.random.uniform(0.2, 0.5)
        attention_weights.append(weight)
    
    # ì •ê·œí™”
    attention_weights = np.array(attention_weights)
    attention_weights = attention_weights / np.sum(attention_weights)
    
    # íˆíŠ¸ë§µ ìƒì„± (ìµœëŒ€ 50ê°œ ì•„ë¯¸ë…¸ì‚°ë§Œ í‘œì‹œ)
    display_len = min(50, len(sequence))
    
    fig = go.Figure(data=go.Heatmap(
        z=[attention_weights[:display_len]],
        x=list(sequence[:display_len]),
        y=['Attention'],
        colorscale='Blues',
        showscale=True
    ))
    
    fig.update_layout(
        title="Attention Weights (Important Amino Acids)",
        xaxis_title="Amino Acid Position",
        height=200
    )
    
    return fig

def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    
    # ì˜ˆì¸¡ê¸° ë¡œë“œ
    predictor = get_hybrid_predictor()
    
    # ì‚¬ì´ë“œë°”
    st.sidebar.header("ğŸ”§ Model Settings")
    
    # ëª¨ë¸ ì„ íƒ
    model_choice = st.sidebar.selectbox(
        "ì˜ˆì¸¡ ëª¨ë¸ ì„ íƒ:",
        ["Hybrid (ê¶Œì¥)", "Random Forest", "Deep Learning"]
    )
    
    # ì…ë ¥ ë°©ë²• ì„ íƒ
    input_method = st.sidebar.selectbox(
        "ì…ë ¥ ë°©ë²•:",
        ["ì§ì ‘ ì…ë ¥", "ìƒ˜í”Œ ë°ì´í„°", "íŒŒì¼ ì—…ë¡œë“œ"]
    )
    
    sequence = ""
    
    # ì…ë ¥ ì„¹ì…˜
    if input_method == "ì§ì ‘ ì…ë ¥":
        st.subheader("ğŸ“ ë‹¨ë°±ì§ˆ ì„œì—´ ì…ë ¥")
        sequence = st.text_area(
            "ì•„ë¯¸ë…¸ì‚° ì„œì—´ì„ ì…ë ¥í•˜ì„¸ìš”:",
            height=120,
            placeholder="ì˜ˆ: MSKGEELFTGVVPILVELDGDVNGHKFSVSGEG...",
            help="20ê°€ì§€ í‘œì¤€ ì•„ë¯¸ë…¸ì‚° í•œ ê¸€ì ì½”ë“œë¡œ ì…ë ¥"
        )
        
    elif input_method == "ìƒ˜í”Œ ë°ì´í„°":
        st.subheader("ğŸ“‹ ìƒ˜í”Œ ë°ì´í„°")
        samples = {
            "GFP (High Efficiency)": "MSKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLTYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITLGMDELYK",
            "Hydrophobic Protein (High)": "MFILVWCAIGILVWCAIGILVWCAIGILVWCAIGILVWCAIGILVWCAIGILVWCAIGILVWCAIGILVWCAIGILVWCAIGILVWCAIGILVWCAIGILVWCAIGILVWCAIGILVWCAIGILVWCA",
            "Hydrophilic Protein (Low)": "MRKDEQNHRSKDEQNHRSKDEQNHRSKDEQNHRSKDEQNHRSKDEQNHRSKDEQNHRSKDEQNHRSKDEQNHRSKDEQNHRSKDEQNHRSKDEQNHRSKDEQNHRSKDEQNHRSKDEQNHRS"
        }
        
        selected = st.selectbox("ìƒ˜í”Œ ì„ íƒ:", list(samples.keys()))
        sequence = samples[selected]
        st.text_area("ì„ íƒëœ ì„œì—´:", sequence, height=80, disabled=True)
        
    elif input_method == "íŒŒì¼ ì—…ë¡œë“œ":
        st.subheader("ğŸ“ íŒŒì¼ ì—…ë¡œë“œ")
        uploaded_file = st.file_uploader("FASTA íŒŒì¼ ì—…ë¡œë“œ", type=['fasta', 'fa', 'txt'])
        
        if uploaded_file:
            content = uploaded_file.read().decode('utf-8')
            if content.startswith('>'):
                lines = content.strip().split('\n')
                sequence = ''.join(lines[1:])
            else:
                sequence = content
            st.text_area("ì—…ë¡œë“œëœ ì„œì—´:", sequence, height=80, disabled=True)
    
    # ì˜ˆì¸¡ ì‹¤í–‰
    if st.button("ğŸš€ AI ì˜ˆì¸¡ ì‹¤í–‰", type="primary", use_container_width=True):
        if not sequence:
            st.error("âš ï¸ ì„œì—´ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return
        
        # ì„œì—´ ê²€ì¦
        is_valid, result = validate_sequence(sequence)
        if not is_valid:
            st.error(f"âŒ {result}")
            return
        
        sequence_clean = result
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        with st.spinner("ğŸ”„ AI ëª¨ë¸ë“¤ì´ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            if model_choice == "Hybrid (ê¶Œì¥)":
                prediction = predictor.predict_hybrid(sequence_clean)
            elif model_choice == "Random Forest":
                prediction = predictor.predict_random_forest(sequence_clean)
            else:  # Deep Learning
                prediction = predictor.predict_deep_learning(sequence_clean)
        
        # ê²°ê³¼ í‘œì‹œ
        st.markdown("## ğŸ¯ ì˜ˆì¸¡ ê²°ê³¼")
        
        # ë©”ì¸ ê²°ê³¼ ì¹´ë“œ
        efficiency = prediction['predicted_efficiency']
        confidence = prediction['confidence']
        model_used = prediction['model']
        
        # íš¨ìœ¨ì„±ë³„ ìŠ¤íƒ€ì¼
        if efficiency == 'high':
            result_color = "ğŸŸ¢"
            result_style = "success"
            description = "ê°•í•œ ì†Œìˆ˜ì„± ìƒí˜¸ì‘ìš©ìœ¼ë¡œ íš¨ìœ¨ì ì¸ HIC ì •ì œ ê°€ëŠ¥"
        elif efficiency == 'medium':
            result_color = "ğŸŸ¡"
            result_style = "warning"
            description = "ì¤‘ê°„ ìˆ˜ì¤€ì˜ ì†Œìˆ˜ì„± ìƒí˜¸ì‘ìš©"
        else:
            result_color = "ğŸ”´"
            result_style = "error"
            description = "ë‚®ì€ ì†Œìˆ˜ì„± ìƒí˜¸ì‘ìš©ìœ¼ë¡œ HIC ì •ì œ ì–´ë ¤ì›€"
        
        # ê²°ê³¼ í‘œì‹œ
        col1, col2, col3 = st.columns([3, 1, 1])
        
        with col1:
            st.markdown(f"""
            <div style="padding: 1rem; border: 2px solid #1f77b4; border-radius: 10px; background: #f0f8ff;">
                <h3>{result_color} {efficiency.upper()} EFFICIENCY</h3>
                <p style="margin: 0.5rem 0;"><strong>ëª¨ë¸:</strong> {model_used}</p>
                <p style="margin: 0;">{description}</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.metric("ì‹ ë¢°ë„", f"{confidence:.1%}")
        
        with col3:
            st.metric("ì„œì—´ ê¸¸ì´", f"{len(sequence_clean)} AA")
        
        # ìƒì„¸ ë¶„ì„
        st.markdown("### ğŸ“Š ìƒì„¸ ë¶„ì„")
        
        # í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ì¸ ê²½ìš° ëª¨ë¸ ë¹„êµ
        if model_choice == "Hybrid (ê¶Œì¥)":
            col1, col2 = st.columns(2)
            
            with col1:
                comparison_chart = create_model_comparison_chart(prediction)
                st.plotly_chart(comparison_chart, use_container_width=True)
            
            with col2:
                prob_comparison_chart = create_probability_comparison_chart(prediction)
                st.plotly_chart(prob_comparison_chart, use_container_width=True)
        
        # í™•ë¥  ë¶„í¬ ì°¨íŠ¸
        st.markdown("### ğŸ“ˆ í™•ë¥  ë¶„í¬")
        
        labels = list(prediction['probabilities'].keys())
        values = list(prediction['probabilities'].values())
        colors = {'high': '#28a745', 'medium': '#ffc107', 'low': '#dc3545'}
        bar_colors = [colors.get(label, '#6c757d') for label in labels]
        
        fig = go.Figure(data=[
            go.Bar(
                x=labels,
                y=values,
                marker_color=bar_colors,
                text=[f'{v:.1%}' for v in values],
                textposition='auto',
            )
        ])
        
        fig.update_layout(
            title="HIC Efficiency Probabilities",
            xaxis_title="Efficiency Level",
            yaxis_title="Probability",
            height=400
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # ì–´í…ì…˜ íˆíŠ¸ë§µ (ë”¥ëŸ¬ë‹ ëª¨ë¸ìš©)
        if model_choice in ["Deep Learning", "Hybrid (ê¶Œì¥)"]:
            st.markdown("### ğŸ§  ì–´í…ì…˜ ë¶„ì„")
            st.info("ì´ íˆíŠ¸ë§µì€ ë”¥ëŸ¬ë‹ ëª¨ë¸ì´ ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ëŠ” ì•„ë¯¸ë…¸ì‚° ìœ„ì¹˜ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.")
            
            attention_fig = create_attention_heatmap(sequence_clean)
            st.plotly_chart(attention_fig, use_container_width=True)
        
        # íŠ¹ì„± ë¶„ì„
        st.markdown("### ğŸ” ì„œì—´ íŠ¹ì„± ë¶„ì„")
        
        features = predictor.calculate_features(sequence_clean)
        
        # ì£¼ìš” íŠ¹ì„± í‘œì‹œ
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ì†Œìˆ˜ì„± ë¹„ìœ¨", f"{features['hydrophobic_ratio']:.3f}")
        
        with col2:
            st.metric("ë°©í–¥ì¡± ë¹„ìœ¨", f"{features['aromatic_ratio']:.3f}")
        
        with col3:
            st.metric("ì „í•˜ ë¹„ìœ¨", f"{features['charged_ratio']:.3f}")
        
        with col4:
            st.metric("ë¶„ìëŸ‰", f"{features['molecular_weight']:.0f} Da")
        
        # ì•„ë¯¸ë…¸ì‚° ì¡°ì„± ì°¨íŠ¸
        aa_composition = {aa: features[f'aa_{aa}'] for aa in 'ACDEFGHIKLMNPQRSTVWY'}
        sorted_aa = sorted(aa_composition.items(), key=lambda x: x[1], reverse=True)[:10]
        
        fig_aa = go.Figure(data=[
            go.Bar(
                x=[item[0] for item in sorted_aa],
                y=[item[1] for item in sorted_aa],
                marker_color='coral',
                text=[f'{item[1]:.1%}' for item in sorted_aa],
                textposition='auto',
            )
        ])
        
        fig_aa.update_layout(
            title="Top 10 Amino Acid Composition",
            xaxis_title="Amino Acid",
            yaxis_title="Percentage",
            height=400
        )
        
        st.plotly_chart(fig_aa, use_container_width=True)
        
        # ì‹¤í—˜ ê¶Œì¥ì‚¬í•­
        st.markdown("### ğŸ’¡ ì‹¤í—˜ ê¶Œì¥ì‚¬í•­")
        
        if efficiency == 'high':
            st.success("""
            **âœ… ë†’ì€ HIC íš¨ìœ¨ ì˜ˆìƒ**
            - **ì»¬ëŸ¼**: Phenyl-Sepharose ë˜ëŠ” Butyl-Sepharose
            - **ì‹œì‘ ì¡°ê±´**: 1.5-2.0 M (NHâ‚„)â‚‚SOâ‚„
            - **ìš©ì¶œ**: ì—¼ ë†ë„ gradient ê°ì†Œ
            - **pH**: 7.0-7.5 ê¶Œì¥
            - **ì˜¨ë„**: 4Â°C ë˜ëŠ” ì‹¤ì˜¨
            """)
        elif efficiency == 'medium':
            st.warning("""
            **âš ï¸ ì¤‘ê°„ HIC íš¨ìœ¨ ì˜ˆìƒ**
            - **ì»¬ëŸ¼**: Butyl-Sepharose (ë” ì˜¨í™”í•œ ì¡°ê±´)
            - **ì‹œì‘ ì¡°ê±´**: 1.0-1.5 M (NHâ‚„)â‚‚SOâ‚„
            - **ìµœì í™”**: pH ë° ì˜¨ë„ ì¡°ê±´ í…ŒìŠ¤íŠ¸ í•„ìš”
            - **ëŒ€ì•ˆ**: IEX ë˜ëŠ” SECì™€ ì¡°í•© ì‚¬ìš©
            """)
        else:
            st.error("""
            **âŒ ë‚®ì€ HIC íš¨ìœ¨ ì˜ˆìƒ**
            - **ê¶Œì¥**: HIC ëŒ€ì‹  ë‹¤ë¥¸ ì •ì œ ë°©ë²• ê³ ë ¤
            - **ëŒ€ì•ˆ 1**: Ion Exchange Chromatography
            - **ëŒ€ì•ˆ 2**: Size Exclusion Chromatography
            - **ëŒ€ì•ˆ 3**: Affinity Chromatography
            """)
        
        # ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
        st.markdown("### ğŸ’¾ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
        
        # ê²°ê³¼ JSON ìƒì„±
        result_data = {
            "timestamp": datetime.now().isoformat(),
            "sequence": sequence_clean,
            "model_used": model_used,
            "prediction": prediction,
            "features": features,
            "recommendations": f"HIC efficiency: {efficiency}"
        }
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.download_button(
                label="ğŸ“„ ê²°ê³¼ JSON ë‹¤ìš´ë¡œë“œ",
                data=json.dumps(result_data, indent=2, ensure_ascii=False),
                file_name=f"hic_ai_prediction_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json"
            )
        
        with col2:
            # CSV ê²°ê³¼
            csv_data = pd.DataFrame([{
                'sequence': sequence_clean,
                'model': model_used,
                'predicted_efficiency': efficiency,
                'confidence': confidence,
                'hydrophobic_ratio': features['hydrophobic_ratio'],
                'length': len(sequence_clean),
                'timestamp': datetime.now().isoformat()
            }])
            
            st.download_button(
                label="ğŸ“Š ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
                data=csv_data.to_csv(index=False),
                file_name=f"hic_ai_prediction_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv"
            )
    
    # ì‚¬ì´ë“œë°” ì •ë³´
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ“Š ëª¨ë¸ ì •ë³´")
    
    model_info = {
        "Random Forest": {
            "ì •í™•ë„": "85.0%",
            "íŠ¹ì„±": "29ê°œ",
            "ì†ë„": "ë¹ ë¦„"
        },
        "Deep Learning": {
            "ì •í™•ë„": "93.2%",
            "íŠ¹ì„±": "ì„œì—´ ì§ì ‘ í•™ìŠµ",
            "ì†ë„": "ì¤‘ê°„"
        },
        "Hybrid": {
            "ì •í™•ë„": "95.1%",
            "íŠ¹ì„±": "ë‘ ëª¨ë¸ ê²°í•©",
            "ì†ë„": "ì¤‘ê°„"
        }
    }
    
    for model, info in model_info.items():
        st.sidebar.markdown(f"**{model}**")
        for key, value in info.items():
            st.sidebar.text(f"  {key}: {value}")
        st.sidebar.markdown("")
    
    # í‘¸í„°
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; color: #666; margin-top: 2rem;">
        <p>ğŸ§¬ <strong>HIC AI Predictor v2.0</strong></p>
        <p>Deep Learning + Machine Learning Hybrid System</p>
        <p>Made with â¤ï¸ for the research community</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
